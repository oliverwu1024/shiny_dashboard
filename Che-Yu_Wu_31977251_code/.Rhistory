series_name <- unique_series[i]
series_data <- data_std[data_std$series_name == series_name, ]
generate_synthetic_series_individual(series_data, n_synthetic, n_scenarios,
frequency, control_params)
})
}
# Process results
successful_results <- results[sapply(results, function(x) x$success)]
failed_results <- results[!sapply(results, function(x) x$success)]
# Combine scenarios
all_scenarios <- list()
for (result in successful_results) {
all_scenarios <- c(all_scenarios, result$scenarios)
}
# Create combined dataframe
if (length(all_scenarios) > 0) {
combined_df <- do.call(rbind, all_scenarios)
# Restore original column names
if (series_column != "series_name") {
names(combined_df)[names(combined_df) == "series_name"] <- series_column
}
if (timestamp_column != "start_timestamp") {
names(combined_df)[names(combined_df) == "start_timestamp"] <- timestamp_column
}
if (value_column != "series_value") {
names(combined_df)[names(combined_df) == "series_value"] <- value_column
}
} else {
combined_df <- data.frame()
}
message(paste("\nSuccessfully processed", length(successful_results),
"out of", n_series, "series"))
return(list(
synthetic_data = combined_df,
successful_results = successful_results,
failed_results = failed_results,
summary = list(
total_series = n_series,
successful = length(successful_results),
failed = length(failed_results),
total_scenarios = length(all_scenarios),
parameters = list(
n_synthetic = n_synthetic,
n_scenarios = n_scenarios,
frequency = frequency
)
)
))
}
# Plot function for a single series with all scenarios
plot_series_with_scenarios <- function(original_data, synthetic_data, series_name,
show_confidence = TRUE, max_scenarios = 15) {
# Get original series data
orig_series <- original_data[original_data$series_name == series_name, ]
# Get synthetic scenarios for this series
synth_series <- synthetic_data[synthetic_data$original_series == series_name, ]
if (nrow(synth_series) == 0) {
warning(paste("No synthetic data found for series:", series_name))
return(NULL)
}
# Prepare data for plotting
orig_series$type <- "Original"
orig_series$scenario <- 0
# Prepare synthetic data
synth_plot <- synth_series[, c("start_timestamp", "series_value", "scenario")]
synth_plot$type <- paste0("Scenario_", synth_plot$scenario)
# Combine for plotting
plot_data <- rbind(
orig_series[, c("start_timestamp", "series_value", "type", "scenario")],
synth_plot
)
# Create base plot
p <- ggplot() +
# Plot original series
geom_line(data = plot_data[plot_data$type == "Original", ],
aes(x = start_timestamp, y = series_value),
color = "black", size = 1.2) +
# Plot synthetic scenarios
geom_line(data = plot_data[plot_data$type != "Original", ],
aes(x = start_timestamp, y = series_value,
group = type, color = as.factor(scenario)),
alpha = 0.6, size = 0.8) +
labs(title = paste("Original and Synthetic Scenarios:", series_name),
x = "Time", y = "Value",
color = "Scenario") +
theme_minimal() +
theme(legend.position = "right")
# Add confidence bands if requested
if (show_confidence && "lower_95" %in% names(synth_series)) {
# Calculate aggregate confidence bands
conf_bands <- synth_series %>%
group_by(start_timestamp) %>%
summarise(
lower = min(lower_95),
upper = max(upper_95),
.groups = 'drop'
)
p <- p +
geom_ribbon(data = conf_bands,
aes(x = start_timestamp, ymin = lower, ymax = upper),
alpha = 0.2, fill = "blue")
}
return(p)
}
cif_df_1<-cif_df[1:120,]
# Regenerate with fixed version
synthetic_cif_fixed <- generate_synthetic_dataset_fixed(
data = cif_df,
n_synthetic = NULL,
n_scenarios = 100,
frequency = 12,
parallel = TRUE,  # Use parallel for speed
n_cores = 4
)
library(Rlgt)
library(forecast)
# Fixed blgt_forecast_from_zero with better randomization
blgt_forecast_from_zero_fixed <- function(rv, h, ns = 1e+06,
initial_level = NULL,
initial_trend = NULL,
initial_seasonal = NULL,
initial_error = NULL,
seed = NULL) {
# set seed to allow different scenarios
if (!is.null(seed)) {
set.seed(seed)
}
# Get model parameters
n = length(rv$y)
n.samples = rv$n.samples
m = rv$m  # seasonality period
# get different draws
I = sample(n.samples, ns, replace = TRUE)
# allow customised trend
if (!is.null(initial_trend)) {
bS = rep(initial_trend, ns)
} else {
bS = rv$bt[I]  #Original: Uses last values from training data
}
#allow customised level
if (!is.null(initial_level)) {
prev.level = rep(initial_level, ns)
} else {
prev.level = rv$lt[I]  # Original: Uses last values from training data
}
#allow customised error
if (!is.null(initial_error)) {
error = rep(initial_error, ns)
} else {
error = rv$et[I] # Original: Uses last values from training data
}
# forecast matrix
yf = matrix(0, ns, h)
# removed yp
# Handle seasonality
seasonal = FALSE
if (m > 1) {
seasonal = TRUE
log.s = matrix(0, ns, m + h)
y.on.l = matrix(0, ns, m + h)
# allow customisable seasonality
if (!is.null(initial_seasonal) && length(initial_seasonal) >= m) {
for (j in 1:m) {
log.s[, j] = log(initial_seasonal[j])
}
y.on.l[, 1:m] = 0
} else {
log.s[, 1:m] = rv$log.s[I, ]  # # Original: Always uses seasonal from end of training
y.on.l[, 1:m] = rv$y.on.l[I, ]
}
}
# Generate forecasts - each path will be different due to different I samples
for (i in 1:h) {
if (seasonal) {
log.s[, i + m] = rv$zeta[I] * y.on.l[, i] + (1 - rv$zeta[I]) * log.s[, i]
log.s[, i + m] = 4 * 1/(1 + exp(-log.s[, i + m])) - 2
}
l = prev.level
if (seasonal) {
exp.val = exp(log.s[, i + m]) * (l + rv$w[I, 1] * l^rv$rho[I] + rv$w[I, 2] * bS)
} else {
exp.val = l + rv$w[I, 1] * l^rv$rho[I] + rv$w[I, 2] * bS
}
scale = sqrt(rv$xi2[I] + rv$sigma2[I] * l^(2 * rv$tau[I]))
#  Generate different random errors for each sample
e = rt(ns, rv$nu[I]) * scale  # This generates different values
yf[, i] = pmax(pmin(exp.val + e, 1e+38), 0.001)
if (seasonal) {
cur.level = pmax(0.001, rv$alpha[I] * yf[, i]/exp(log.s[, i + m]) +
(1 - rv$alpha[I]) * prev.level)
} else {
cur.level = pmax(0.001, rv$alpha[I] * yf[, i] + (1 - rv$alpha[I]) * prev.level)
}
idx <- which(yf[, i] <= 0.001)
cur.level[idx] <- prev.level[idx]
if (seasonal) {
y.on.l[, i + m] = log(yf[, i]/cur.level)
y.on.l[idx, i + m] <- y.on.l[idx, i]
}
bS = rv$beta[I] * (cur.level - prev.level) + (1 - rv$beta[I]) * bS
prev.level = cur.level
}
# Return different quantiles to show variation
list(
yf.med = apply(yf, 2, function(x) { quantile(x, 0.5) }),
yf.CI05 = apply(yf, 2, function(x) { quantile(x, 0.025) }),
yf.CI95 = apply(yf, 2, function(x) { quantile(x, 0.975) }),
yf = yf
)
}
# Generate individual paths
generate_synthetic_series_individual <- function(series_data, n_synthetic = NULL,
n_scenarios = 1, frequency = 12,
control_params = NULL) {
# Extract series information
series_name <- unique(series_data$series_name)[1]
series_values <- series_data$series_value
# Check for additional columns
extra_cols <- setdiff(names(series_data), c("series_name", "start_timestamp", "series_value"))
extra_data <- if(length(extra_cols) > 0) {
series_data[1, extra_cols, drop = FALSE]
} else {
NULL
}
if (is.null(n_synthetic)) {
n_synthetic <- length(series_values)
}
# Convert to ts object
ts_data <- ts(series_values, frequency = frequency)
message(paste("Fitting RLGT model for series:", series_name))
# Set control parameters
if (is.null(control_params)) {
control_params <- rlgt.control(
)
}
tryCatch({
# Fit model
rlgt_model <- rlgt(
y = ts_data,
method = "Gibbs",
control = control_params,
verbose = FALSE
)
# Customise initial conditions
initial_level <- mean(series_values[1:min(frequency, length(series_values))])
initial_trend <- 0
if (frequency > 1) {
initial_seasonal <- rep(1, frequency)
if (length(series_values) >= frequency) {
first_year <- series_values[1:frequency]
initial_seasonal <- first_year / mean(first_year)
}
} else {
initial_seasonal <- NULL
}
# Generate scenarios with different random paths
scenarios_list <- list()
for (scenario in 1:n_scenarios) {
# Generate a SINGLE path for this scenario
n_paths <- 1000  # Generate numbers different paths to choose (can customise)
synthetic_result <- blgt_forecast_from_zero_fixed(
rv = rlgt_model,
h = n_synthetic,
ns = n_paths,  # paths
initial_level = initial_level,
initial_trend = initial_trend,
initial_seasonal = initial_seasonal,
seed = NULL
)
# Pick a random path from the generated paths
path_idx <- sample(1:n_paths, 1)
synthetic_values <- synthetic_result$yf[path_idx, ]
# Create scenario data
scenario_df <- data.frame(
series_name = paste0(series_name, "_synthetic_", scenario),
start_timestamp = 1:n_synthetic,
series_value = synthetic_values,
original_series = series_name,
scenario = scenario,
lower_95 = synthetic_result$yf.CI05,
upper_95 = synthetic_result$yf.CI95
)
# Add extra columns if they exist
if (!is.null(extra_data)) {
for (col in names(extra_data)) {
scenario_df[[col]] <- extra_data[[col]]
}
}
scenarios_list[[scenario]] <- scenario_df
}
return(list(
success = TRUE,
scenarios = scenarios_list,
model = rlgt_model,
series_name = series_name,
initial_conditions = list(
level = initial_level,
trend = initial_trend,
seasonal = initial_seasonal
)
))
}, error = function(e) {
message(paste("Error processing", series_name, ":", e$message))
return(list(
success = FALSE,
error = e$message,
series_name = series_name
))
})
}
# Update the main generation function to use the fixed approach
generate_synthetic_dataset_fixed <- function(data, n_synthetic = NULL,
n_scenarios = 1, frequency = 12,
parallel = TRUE, n_cores = NULL,
control_params = NULL,
series_column = "series_name",
timestamp_column = "start_timestamp",
value_column = "series_value") {
# Validate required columns
required_cols <- c(series_column, timestamp_column, value_column)
if (!all(required_cols %in% names(data))) {
stop(paste("Missing required columns. Expected:", paste(required_cols, collapse = ", ")))
}
# Standardize column names
data_std <- data
names(data_std)[names(data_std) == series_column] <- "series_name"
names(data_std)[names(data_std) == timestamp_column] <- "start_timestamp"
names(data_std)[names(data_std) == value_column] <- "series_value"
# Get unique series
unique_series <- unique(data_std$series_name)
n_series <- length(unique_series)
message(paste("Processing", n_series, "series from dataset"))
message(paste("Generating", n_scenarios, "scenarios per series"))
# Process each series
if (parallel && n_series > 1) {
if (is.null(n_cores)) {
n_cores <- min(parallel::detectCores() - 1, 4)
}
cl <- parallel::makeCluster(n_cores)
parallel::clusterEvalQ(cl, {
library(Rlgt)
library(forecast)
})
# Export necessary functions
parallel::clusterExport(cl, c("blgt_forecast_from_zero_fixed",
"generate_synthetic_series_individual",
"data_std", "n_synthetic", "n_scenarios",
"frequency", "control_params"),
envir = environment())
results <- parallel::parLapply(cl, unique_series, function(series_name) {
series_data <- data_std[data_std$series_name == series_name, ]
generate_synthetic_series_individual(series_data, n_synthetic, n_scenarios,
frequency, control_params)
})
parallel::stopCluster(cl)
} else {
# Sequential processing
results <- lapply(seq_along(unique_series), function(i) {
if (i %% 10 == 0) {
message(paste("Processing series", i, "of", n_series))
}
series_name <- unique_series[i]
series_data <- data_std[data_std$series_name == series_name, ]
generate_synthetic_series_individual(series_data, n_synthetic, n_scenarios,
frequency, control_params)
})
}
# Process results
successful_results <- results[sapply(results, function(x) x$success)]
failed_results <- results[!sapply(results, function(x) x$success)]
# Combine scenarios
all_scenarios <- list()
for (result in successful_results) {
all_scenarios <- c(all_scenarios, result$scenarios)
}
# Create combined dataframe
if (length(all_scenarios) > 0) {
combined_df <- do.call(rbind, all_scenarios)
# Restore original column names
if (series_column != "series_name") {
names(combined_df)[names(combined_df) == "series_name"] <- series_column
}
if (timestamp_column != "start_timestamp") {
names(combined_df)[names(combined_df) == "start_timestamp"] <- timestamp_column
}
if (value_column != "series_value") {
names(combined_df)[names(combined_df) == "series_value"] <- value_column
}
} else {
combined_df <- data.frame()
}
message(paste("\nSuccessfully processed", length(successful_results),
"out of", n_series, "series"))
return(list(
synthetic_data = combined_df,
successful_results = successful_results,
failed_results = failed_results,
summary = list(
total_series = n_series,
successful = length(successful_results),
failed = length(failed_results),
total_scenarios = length(all_scenarios),
parameters = list(
n_synthetic = n_synthetic,
n_scenarios = n_scenarios,
frequency = frequency
)
)
))
}
# Plot function for a single series with all scenarios
plot_series_with_scenarios <- function(original_data, synthetic_data, series_name,
show_confidence = TRUE, max_scenarios = 15) {
# Get original series data
orig_series <- original_data[original_data$series_name == series_name, ]
# Get synthetic scenarios for this series
synth_series <- synthetic_data[synthetic_data$original_series == series_name, ]
if (nrow(synth_series) == 0) {
warning(paste("No synthetic data found for series:", series_name))
return(NULL)
}
# Prepare data for plotting
orig_series$type <- "Original"
orig_series$scenario <- 0
# Prepare synthetic data
synth_plot <- synth_series[, c("start_timestamp", "series_value", "scenario")]
synth_plot$type <- paste0("Scenario_", synth_plot$scenario)
# Combine for plotting
plot_data <- rbind(
orig_series[, c("start_timestamp", "series_value", "type", "scenario")],
synth_plot
)
# Create base plot
p <- ggplot() +
# Plot original series
geom_line(data = plot_data[plot_data$type == "Original", ],
aes(x = start_timestamp, y = series_value),
color = "black", size = 1.2) +
# Plot synthetic scenarios
geom_line(data = plot_data[plot_data$type != "Original", ],
aes(x = start_timestamp, y = series_value,
group = type, color = as.factor(scenario)),
alpha = 0.6, size = 0.8) +
labs(title = paste("Original and Synthetic Scenarios:", series_name),
x = "Time", y = "Value",
color = "Scenario") +
theme_minimal() +
theme(legend.position = "right")
# Add confidence bands if requested
if (show_confidence && "lower_95" %in% names(synth_series)) {
# Calculate aggregate confidence bands
conf_bands <- synth_series %>%
group_by(start_timestamp) %>%
summarise(
lower = min(lower_95),
upper = max(upper_95),
.groups = 'drop'
)
p <- p +
geom_ribbon(data = conf_bands,
aes(x = start_timestamp, ymin = lower, ymax = upper),
alpha = 0.2, fill = "blue")
}
return(p)
}
# Regenerate with fixed version
synthetic_cif_fixed <- generate_synthetic_dataset_fixed(
data = cif_df,
n_synthetic = NULL,
n_scenarios = 100,
frequency = 12,
parallel = TRUE,  # Use parallel for speed
n_cores = 4
)
# Plot series
for (i in 1:72) {
series_name <- unique(cif_df$series_name)[i]
p <- plot_series_with_scenarios(cif_df, synthetic_cif_fixed$synthetic_data, series_name, show_confidence = FALSE)
print(p)
}
View(synthetic_cif_fixed)
cif_syn<-synthetic_cif_fixed$synthetic_data
View(cif_syn)
str(cif_syn)
cif_syn<-synthetic_cif_fixed$synthetic_data
cif_syn$ts <- cif_syn$start_timestamp          # rename for clarity
library(dplyr)
library(arrow)
install.packages("arrow")
cif_syn<-synthetic_cif_fixed$synthetic_data
cif_syn$ts <- cif_syn$start_timestamp          # rename for clarity
library(dplyr)
library(arrow)
out_dir <- "synthetic_tasks"
dir.create(out_dir, showWarnings = FALSE)
cif_syn %>%
mutate(series_id = paste(series_name, scenario, sep = "_"),
ts        = start_timestamp) %>%           # keep the ordinal step
select(series_id, ts, y = series_value) %>%       # drop other columns
group_by(series_id) %>%
group_walk(~ write_feather(.x,
file.path(out_dir, paste0(.y$series_id, ".feather")),
compression = "uncompressed"))
View(cif_syn)
setwd("D:/24S2/5147 data visualisation/DVP/Che-Yu_Wu_31977251_code")
library(shiny); runApp('Che-Yu_Wu_31977251_code.R')
install.packages('rsconnect')
rsconnect::setAccountInfo(name='oliverwu1024',
token='A04F9D1AFB88312DF5B6847DBD75EBB5',
secret='<SECRET>')
runApp('Che-Yu_Wu_31977251_code.R')
runApp('Che-Yu_Wu_31977251_code.R')
